{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "56c4eb6c-b40b-4944-974c-61a9bacacc0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-26 22:55:28,932 - INFO - Starting training phase...\n",
      "2024-10-26 22:55:28,933 - INFO - Found 0 training documents\n",
      "2024-10-26 22:55:28,933 - INFO - Prepared 0 training examples\n",
      "[2024-10-26 22:55:29,013] [INFO] Created vocabulary\n",
      "2024-10-26 22:55:29,013 - INFO - Created vocabulary\n",
      "[2024-10-26 22:55:29,014] [INFO] Finished initializing nlp object\n",
      "2024-10-26 22:55:29,014 - INFO - Finished initializing nlp object\n",
      "2024-10-26 22:55:29,128 - INFO - Iteration 1, Losses: {}\n",
      "2024-10-26 22:55:29,128 - INFO - Iteration 2, Losses: {}\n",
      "2024-10-26 22:55:29,128 - INFO - Iteration 3, Losses: {}\n",
      "2024-10-26 22:55:29,128 - INFO - Iteration 4, Losses: {}\n",
      "2024-10-26 22:55:29,128 - INFO - Iteration 5, Losses: {}\n",
      "2024-10-26 22:55:29,129 - INFO - Iteration 6, Losses: {}\n",
      "2024-10-26 22:55:29,129 - INFO - Iteration 7, Losses: {}\n",
      "2024-10-26 22:55:29,129 - INFO - Iteration 8, Losses: {}\n",
      "2024-10-26 22:55:29,129 - INFO - Iteration 9, Losses: {}\n",
      "2024-10-26 22:55:29,130 - INFO - Iteration 10, Losses: {}\n",
      "2024-10-26 22:55:29,130 - INFO - Iteration 11, Losses: {}\n",
      "2024-10-26 22:55:29,130 - INFO - Iteration 12, Losses: {}\n",
      "2024-10-26 22:55:29,130 - INFO - Iteration 13, Losses: {}\n",
      "2024-10-26 22:55:29,130 - INFO - Iteration 14, Losses: {}\n",
      "2024-10-26 22:55:29,130 - INFO - Iteration 15, Losses: {}\n",
      "2024-10-26 22:55:29,131 - INFO - Iteration 16, Losses: {}\n",
      "2024-10-26 22:55:29,131 - INFO - Iteration 17, Losses: {}\n",
      "2024-10-26 22:55:29,131 - INFO - Iteration 18, Losses: {}\n",
      "2024-10-26 22:55:29,131 - INFO - Iteration 19, Losses: {}\n",
      "2024-10-26 22:55:29,131 - INFO - Iteration 20, Losses: {}\n",
      "2024-10-26 22:55:29,132 - INFO - Iteration 21, Losses: {}\n",
      "2024-10-26 22:55:29,132 - INFO - Iteration 22, Losses: {}\n",
      "2024-10-26 22:55:29,132 - INFO - Iteration 23, Losses: {}\n",
      "2024-10-26 22:55:29,132 - INFO - Iteration 24, Losses: {}\n",
      "2024-10-26 22:55:29,132 - INFO - Iteration 25, Losses: {}\n",
      "2024-10-26 22:55:29,132 - INFO - Iteration 26, Losses: {}\n",
      "2024-10-26 22:55:29,133 - INFO - Iteration 27, Losses: {}\n",
      "2024-10-26 22:55:29,133 - INFO - Iteration 28, Losses: {}\n",
      "2024-10-26 22:55:29,133 - INFO - Iteration 29, Losses: {}\n",
      "2024-10-26 22:55:29,133 - INFO - Iteration 30, Losses: {}\n",
      "2024-10-26 22:55:29,183 - INFO - Model saved to trained_models/panchayat_raj_model\n",
      "2024-10-26 22:55:29,183 - INFO - Starting testing phase...\n",
      "2024-10-26 22:55:29,244 - INFO - Successfully read PDF: /Users/srikar/Desktop/Panchayat Raj/Test/GO MS NO. 174.pdf - Seri.ap.gov.in.pdf\n",
      "2024-10-26 22:55:29,357 - INFO - Results saved to extracted_info.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracted Information:\n",
      "\n",
      "**BUDGET_AMOUNTS**:\n",
      "\n",
      "**DATES**:\n",
      "\n",
      "**FILE_NUMBERS**:\n",
      "\n",
      "**ACCOUNT_HEADS**:\n",
      "\n",
      "**DEPARTMENTS**:\n",
      "\n",
      "**OFFICIAL_DESIGNATIONS**:\n",
      "\n",
      "**TECHNICAL_TERMS**:\n",
      "\n",
      "**SUMMARY**:\n",
      "**GOVERNMENT OF ANDHRA PRADESH \n",
      "ABSTRACT \n",
      "LOANS AND ADVANCES— House Building Advance—Admissibility in Revised Pay  \n",
      "Scales, 2010 – Recommendation of Ninth Pay Revision  Commission -- Accepted – Orders \n",
      "–Issued. \n",
      "                                FINANCE (A & L) DEPARTMENT \n",
      "G.O. Ms. No.174                                                                              Dated:15-05-2010.  \n",
      "                                                                                                   Rea d the following:- \n",
      "1. G.O. (P) No.77, Finance (FW: A&L) Department, dt  03-04-2006. \n",
      "2. G.O.Ms.No. 438, General Administration (Spl. A) Department, dt 7-7-2008. \n",
      "3. G.O. (P) No. 52, Finance (PC.I) Department, dt 2 5-2-2010. \n",
      "                                                  * ** \n",
      "ORDER: \n",
      " \n",
      " In the Government Order 3rd read above, based on the recommendations of Ninth \n",
      "Pay Revision Commission, orders were issued impleme nting the Revised Pay Scales, \n",
      "2010 to the State Government employees. \n",
      " \n",
      "2.         The Ninth Pay Revision Commission among others has recommended \n",
      "enhancement of eligibility ceiling in respect of Ho use Building Advance to the State \n",
      "Government employees, in the Revised Pay Scales 201 0. \n",
      " \n",
      "3.         Government, after careful consideration of the recommendations of the Ninth Pay \n",
      "Revision Commission and in modification of the orde rs issued in Government order1st  \n",
      "read above, hereby enhance the existing ceiling of House Building Advance to the State \n",
      "Government employees, for the purchase of ready bui lt house/ flat, for purchase of site-\n",
      "cum-construction of new house/ flat and for the con struction of new house/ flat on the site \n",
      "already owned by the employee as follows:- \n",
      " \n",
      "Sl.No. Pay ranges in Revised \n",
      "Pay Scales, 2010 Enhanced \n",
      "Maximum ceiling Eligibility Rate of \n",
      "interest \n",
      "a) Employees drawing \n",
      "basic pay upto \n",
      "Rs.13,660 per month Rs. 5.00 lakhs Or 72 times of \n",
      "basic pay \n",
      "whichever is less For Class.IV \n",
      "employees  @ \n",
      "5.00% p.a. \n",
      "For others  @ \n",
      "5.50% p.a. \n",
      "b) Employees drawing \n",
      "basic pay above Rs. \n",
      "13,660 p.m. and upto \n",
      "Rs. 21,820 p.m. Rs. 6.00 lakhs          -do- -do- \n",
      "c) Employees drawing \n",
      "basic pay above \n",
      "Rs.21,820 p.m. and \n",
      "upto Rs. 31,550 p.m. Rs. 7.50 lakhs           -do- -do- \n",
      "d) Employees drawing \n",
      "basic pay above Rs. \n",
      "31,550 p.m. Rs. 10.00 lakhs           -do- -do- \n",
      "e)  All India Service \n",
      "Officers working in \n",
      "the State \n",
      "(All India service \n",
      "officers working in \n",
      "the State may be \n",
      "given the option to \n",
      "choose either the \n",
      "State Govt. ceiling or \n",
      "to adopt Govt. of \n",
      "India rules) Rs. 15.00 lakhs Or 50 times of \n",
      "basic pay \n",
      "whichever is less -do- \n",
      " \n",
      " 4.      Further, Government hereby enhance the exi sting ceiling of House Building \n",
      "Advance for repairs/ extension etc., to twenty time s of basic pay in the Revised Pay \n",
      "Scales, 2010 or Rs. 2.00 lakhs which ever is less .  \n",
      "  \n",
      "5. Government also considered for purchase of house  site and hereby sanction ten \n",
      "times of basic pay in the Revised Pay Scales, 2010 or Rs 1.00 lakh which ever is less.       \n",
      "                                                \n",
      "6. Government further order that the following exis ting recovery pattern shall \n",
      "continue:- \n",
      " \n",
      "House Building Advance  :   300 monthly installment s i.e. 240 principal + 60 interest. \n",
      " \n",
      "Repairs                              :   90 monthly  installments i.e. 75 principal + 15 interest. \n",
      " \n",
      "House site                          :   72 monthly installments i.e. 60 principal + 12 interest.    \n",
      " \n",
      "7. Penal Interest will be charged at double the rat e of normal interest in case the \n",
      "advance are mis-utilized or not utilized at all and  at 1 ½  % times the normal rates for non-\n",
      "compliance with formalities. \n",
      " \n",
      "8.       All other conditions governing the sanctio n of House Building Advance under the \n",
      "existing Rules will continue. \n",
      " \n",
      "9.       These orders shall come into force from 1-4-2010. \n",
      " \n",
      "10.        The G.O. is available on the Internet an d can be accessed at the address \n",
      "http://www.aponline.gov.in . and http://www.apfinance.gov.in . \n",
      " \n",
      "(BY ORDER AND IN THE NAME OF THE GOVERNOR OF ANDHRA  PRADESH) \n",
      " \n",
      "                                                                                    L.V.SUBRAHAMANYAM \n",
      "                                                                     PRL.  SECRETARY TO GOVERNMENT (FP) \n",
      " \n",
      "To \n",
      "All Departments of Secretariat. \n",
      "All Heads of Departments. \n",
      "The Accountant General, A.P., Hyderabad. \n",
      "The Pay & Accounts Officers, A.P., Hyderabad. \n",
      "The Director of Treasuries & Accounts, A.P., Hydera bad. \n",
      "The Director of State Audit, A.P., Hyderabad. \n",
      "The Director of Insurance, A.P., Hyderabad. \n",
      "The Commissioner of Small Savings & State Lotteries , A.P., Hyd. \n",
      "The Secretary, A.P.Public Service Commission, Hyder abad. \n",
      "The Secretary to Governor, Raj Bhavan, Hyderabad. \n",
      "The Registrar, A.P.High Court, Hyderabad. \n",
      "The Registrar, A.P.Administrative Tribunal, Hyderab ad. \n",
      "All District Collectors. \n",
      "All District Session Judges. \n",
      "All Superintendents of Police. \n",
      "All District Treasury Officers. \n",
      "All Directors of Account of Projects. \n",
      "All District Developments 0fficers of Zilla Praja P arishads through Collectors. \n",
      "All District Panchayat Raj Officers. \n",
      "All District Educational Officers. \n",
      "All the Secretaries of Zilla Grandhalaya Samsthas t hrough the Director of Public \n",
      "Libraries, Hyderabad. \n",
      "All the Secretaries of Agricultural Market Committe es through the Directors of   \n",
      "      Marketing, Hyderabad. \n",
      "All Commissioners /Special Officers of Municipaliti es. \n",
      "The Director, Government Printing Press, A.P., Hyde rabad for publication  \n",
      "        in the Andhra Pradesh Gazette. \n",
      "Copy to: \n",
      "The A.P.Secretariat Service Association, Secretaria t Building, A.P., Hyd. \n",
      "All the Recognized Service Associations. \n",
      "The Stock File/Spare Copies.    \n",
      " \n",
      "                                        //FORWARDED  BY ORDE// \n",
      " \n",
      " \n",
      "                                                                                               SECTION  OFFICER.**\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import spacy\n",
    "from spacy.tokens import DocBin\n",
    "from spacy.training import Example\n",
    "import re\n",
    "import xml.etree.ElementTree as ET\n",
    "from pathlib import Path\n",
    "import logging\n",
    "import PyPDF2\n",
    "import json\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class PanchayatRajProcessor:\n",
    "    def __init__(self, model_dir=\"./trained_models\"):\n",
    "        \"\"\"Initialize the processor\"\"\"\n",
    "        self.nlp = spacy.blank(\"en\")\n",
    "        self.model_dir = Path(model_dir)\n",
    "        self.model_dir.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        # Define entity labels\n",
    "        self.CUSTOM_ENTITIES = [\n",
    "            \"BUDGET_AMOUNT\",\n",
    "            \"DATE\",\n",
    "            \"FILE_NUMBER\",\n",
    "            \"ACCOUNT_HEAD\",\n",
    "            \"DEPARTMENT\",\n",
    "            \"OFFICIAL_DESIGNATION\",\n",
    "            \"TECHNICAL_TERM\"\n",
    "        ]\n",
    "        \n",
    "        # Compile regex patterns\n",
    "        self.patterns = {\n",
    "            'BUDGET_AMOUNT': r'Rs\\.?\\s*([\\d,]+(?:\\.\\d{2})?)\\/?-',\n",
    "            'DATE': r'\\d{2}-\\d{2}-\\d{4}',\n",
    "            'FILE_NUMBER': r'G\\.O\\.RT\\.No\\.\\s*\\d+',\n",
    "            'ACCOUNT_HEAD': r'\\d{14}',\n",
    "            'DEPARTMENT': r'[A-Z&]{2,}(?:\\s+[A-Z]+)*\\s+DEPARTMENT',\n",
    "            'OFFICIAL_DESIGNATION': r'(?:Commissioner|Director|Secretary|PRINCIPAL SECRETARY|GOVERNOR)',\n",
    "            'TECHNICAL_TERM': r'(?:Finance Commission|Basic grant|Untied|RLBS)'\n",
    "        }\n",
    "\n",
    "    def read_pdf(self, pdf_path):\n",
    "        \"\"\"\n",
    "        Read text content from PDF file\n",
    "        \n",
    "        Args:\n",
    "            pdf_path (str): Path to PDF file\n",
    "            \n",
    "        Returns:\n",
    "            str: Extracted text from PDF\n",
    "        \"\"\"\n",
    "        try:\n",
    "            with open(pdf_path, 'rb') as file:\n",
    "                pdf_reader = PyPDF2.PdfReader(file)\n",
    "                text = \"\"\n",
    "                for page in pdf_reader.pages:\n",
    "                    text += page.extract_text() + \"\\n\"\n",
    "                logger.info(f\"Successfully read PDF: {pdf_path}\")\n",
    "                return text\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error reading PDF {pdf_path}: {str(e)}\")\n",
    "            return None\n",
    "\n",
    "    def read_training_data(self, directory):\n",
    "        \"\"\"\n",
    "        Read XML files from training directory\n",
    "        \n",
    "        Args:\n",
    "            directory (str): Path to training data directory\n",
    "            \n",
    "        Returns:\n",
    "            list: List of parsed XML documents\n",
    "        \"\"\"\n",
    "        documents = []\n",
    "        dir_path = Path(directory)\n",
    "        \n",
    "        try:\n",
    "            for xml_file in dir_path.glob(\"*.xml\"):\n",
    "                tree = ET.parse(xml_file)\n",
    "                root = tree.getroot()\n",
    "                documents.extend(root.findall(\".//document\"))\n",
    "                logger.info(f\"Successfully processed {xml_file}\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error reading training data: {str(e)}\")\n",
    "            raise\n",
    "            \n",
    "        return documents\n",
    "\n",
    "    def prepare_training_data(self, xml_documents):\n",
    "        \"\"\"Prepare training data from XML documents\"\"\"\n",
    "        training_data = []\n",
    "        \n",
    "        for doc in xml_documents:\n",
    "            try:\n",
    "                content = doc.find(\"document_content\").text\n",
    "                entities = []\n",
    "                \n",
    "                # Find entities using patterns\n",
    "                for label, pattern in self.patterns.items():\n",
    "                    for match in re.finditer(pattern, content):\n",
    "                        entities.append((match.start(), match.end(), label))\n",
    "                \n",
    "                # Sort and filter overlapping entities\n",
    "                entities = sorted(entities, key=lambda x: x[0])\n",
    "                filtered_entities = []\n",
    "                last_end = 0\n",
    "                \n",
    "                for start, end, label in entities:\n",
    "                    if start >= last_end:\n",
    "                        filtered_entities.append((start, end, label))\n",
    "                        last_end = end\n",
    "                \n",
    "                training_data.append((content, {\"entities\": filtered_entities}))\n",
    "                \n",
    "            except Exception as e:\n",
    "                logger.error(f\"Error preparing training data: {str(e)}\")\n",
    "                continue\n",
    "                \n",
    "        return training_data\n",
    "\n",
    "    def train_model(self, training_data, iterations=30):\n",
    "        \"\"\"Train the NER model\"\"\"\n",
    "        try:\n",
    "            # Add NER pipeline\n",
    "            if \"ner\" not in self.nlp.pipe_names:\n",
    "                ner = self.nlp.create_pipe(\"ner\")\n",
    "                self.nlp.add_pipe(\"ner\", last=True)\n",
    "            \n",
    "            # Add labels\n",
    "            ner = self.nlp.get_pipe(\"ner\")\n",
    "            for label in self.CUSTOM_ENTITIES:\n",
    "                ner.add_label(label)\n",
    "            \n",
    "            # Train\n",
    "            other_pipes = [pipe for pipe in self.nlp.pipe_names if pipe != \"ner\"]\n",
    "            with self.nlp.disable_pipes(*other_pipes):\n",
    "                optimizer = self.nlp.begin_training()\n",
    "                for itn in range(iterations):\n",
    "                    losses = {}\n",
    "                    for text, annotations in training_data:\n",
    "                        doc = self.nlp.make_doc(text)\n",
    "                        example = Example.from_dict(doc, annotations)\n",
    "                        self.nlp.update([example], drop=0.5, losses=losses)\n",
    "                    logger.info(f\"Iteration {itn + 1}, Losses: {losses}\")\n",
    "                    \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error during training: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "    def extract_information(self, text):\n",
    "        \"\"\"Extract information from text and format output\"\"\"\n",
    "        try:\n",
    "            doc = self.nlp(text)\n",
    "            \n",
    "            extracted_info = {\n",
    "                \"budget_amounts\": [],\n",
    "                \"dates\": [],\n",
    "                \"file_numbers\": [],\n",
    "                \"account_heads\": [],\n",
    "                \"departments\": [],\n",
    "                \"official_designations\": [],\n",
    "                \"technical_terms\": [],\n",
    "                \"summary\": \"\"\n",
    "            }\n",
    "            \n",
    "            # Extract entities\n",
    "            for ent in doc.ents:\n",
    "                category = ent.label_.lower()\n",
    "                if category in extracted_info:\n",
    "                    extracted_info[category].append({\n",
    "                        \"text\": ent.text,\n",
    "                        \"start\": ent.start_char,\n",
    "                        \"end\": ent.end_char\n",
    "                    })\n",
    "            \n",
    "            # Generate summary\n",
    "            paragraphs = text.split('\\n\\n')\n",
    "            if paragraphs:\n",
    "                extracted_info[\"summary\"] = paragraphs[0].strip()\n",
    "            \n",
    "            # Format the extracted information\n",
    "            formatted_output = \"\\nExtracted Information:\\n\"\n",
    "            for category, items in extracted_info.items():\n",
    "                formatted_output += f\"\\n**{category.upper()}**:\\n\"\n",
    "                if isinstance(items, list) and items:\n",
    "                    for item in items:\n",
    "                        formatted_output += f\"- **{item['text']}** (Start: {item['start']}, End: {item['end']})\\n\"\n",
    "                elif isinstance(items, str) and items:\n",
    "                    formatted_output += f\"**{items}**\\n\"\n",
    "                    \n",
    "            return formatted_output\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error extracting information: {str(e)}\")\n",
    "            return None\n",
    "\n",
    "    def save_model(self, model_name=\"panchayat_raj_model\"):\n",
    "        \"\"\"Save the trained model\"\"\"\n",
    "        try:\n",
    "            model_path = self.model_dir / model_name\n",
    "            self.nlp.to_disk(model_path)\n",
    "            logger.info(f\"Model saved to {model_path}\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error saving model: {str(e)}\")\n",
    "\n",
    "    def load_model(self, model_name=\"panchayat_raj_model\"):\n",
    "        \"\"\"Load a trained model\"\"\"\n",
    "        try:\n",
    "            model_path = self.model_dir / model_name\n",
    "            self.nlp = spacy.load(model_path)\n",
    "            logger.info(f\"Model loaded from {model_path}\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error loading model: {str(e)}\")\n",
    "\n",
    "    def save_results(self, results, output_file=\"extracted_info.json\"):\n",
    "        \"\"\"Save extracted information to JSON file\"\"\"\n",
    "        try:\n",
    "            with open(output_file, 'w', encoding='utf-8') as f:\n",
    "                json.dump(results, f, indent=2, ensure_ascii=False)\n",
    "            logger.info(f\"Results saved to {output_file}\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error saving results: {str(e)}\")\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main execution function\"\"\"\n",
    "    # Initialize processor\n",
    "    processor = PanchayatRajProcessor()\n",
    "    \n",
    "    try:\n",
    "        # Training Phase\n",
    "        logger.info(\"Starting training phase...\")\n",
    "        \n",
    "        # Read and process training documents\n",
    "        training_docs = processor.read_training_data(\"/Users/srikar/Desktop/Panchayat Raj\")\n",
    "        logger.info(f\"Found {len(training_docs)} training documents\")\n",
    "        \n",
    "        # Prepare training data\n",
    "        training_data = processor.prepare_training_data(training_docs)\n",
    "        logger.info(f\"Prepared {len(training_data)} training examples\")\n",
    "        \n",
    "        # Train the model\n",
    "        processor.train_model(training_data)\n",
    "        \n",
    "        # Save the trained model\n",
    "        processor.save_model()\n",
    "        \n",
    "        # Testing Phase\n",
    "        logger.info(\"Starting testing phase...\")\n",
    "        \n",
    "        # Read test document\n",
    "        test_pdf_path = \"/Users/srikar/Desktop/Panchayat Raj/Test/GO MS NO. 174.pdf - Seri.ap.gov.in.pdf\"\n",
    "        test_text = processor.read_pdf(test_pdf_path)\n",
    "        \n",
    "        if test_text:\n",
    "            # Extract information from test document\n",
    "            results = processor.extract_information(test_text)\n",
    "            \n",
    "            # Save results to JSON file\n",
    "            processor.save_results(results)\n",
    "            \n",
    "            # Print results\n",
    "            print(results)\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error in main execution: {str(e)}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b3d3586-d827-485e-979c-39d56aa5b894",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
